{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classification_lstm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP07cbmlCPdqEF9s8aiEbKH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-dyxhzrquDYb","executionInfo":{"status":"ok","timestamp":1622006673063,"user_tz":-540,"elapsed":1535,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"e1ac5dad-3e0f-46d1-dfcc-f67ba1db2606"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ekr2fFT7ulCp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622006673064,"user_tz":-540,"elapsed":7,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"bbce4800-26d2-4134-acdb-df9d56686a9b"},"source":["%tensorflow_version 1.x "],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LRJiASHuq4D","executionInfo":{"status":"ok","timestamp":1622006677614,"user_tz":-540,"elapsed":3003,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"df6bea84-ec16-482b-bc0a-6e891df41d8f"},"source":["!pip install tensorflow-hub #텐서플로우 허브로부터 사전훈련된모델 이용가능"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (1.19.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (3.12.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (56.1.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5AA3jF54un7r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622006683361,"user_tz":-540,"elapsed":5749,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"3085e35c-2b38-4300-b156-c9410ab76ec2"},"source":["import tensorflow_hub as hub\n","import tensorflow as tf\n","from keras import backend as K"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"V6oEhw1ruH8I","executionInfo":{"status":"ok","timestamp":1622006683361,"user_tz":-540,"elapsed":16,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["import pandas as pd\n","import numpy as np\n","import re\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import StratifiedKFold\n","\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.utils import plot_model, to_categorical\n","from tensorflow.keras.optimizers import Adam\n","\n","from keras.utils import np_utils\n","\n","import warnings \n","warnings.filterwarnings(action='ignore')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dqQPbw6us1n","executionInfo":{"status":"ok","timestamp":1622006683362,"user_tz":-540,"elapsed":15,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["#경로 설정\n","import os\n","os.chdir('/content/drive/MyDrive/Project/[sai]perfume')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"II0K5IiViuYX"},"source":["# 데이터 준비\n","- 테이블 합치기\n","- 입력형태 맞추기"]},{"cell_type":"code","metadata":{"id":"4z9RLfAHunvR","executionInfo":{"status":"ok","timestamp":1622006691703,"user_tz":-540,"elapsed":8356,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["data = pd.read_csv(\"data/preprocessed.csv\",encoding=\"utf-8\")\n","label= pd.read_csv(\"data/labeled_data.csv\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPM0XOb5x9IG","executionInfo":{"status":"ok","timestamp":1622006691711,"user_tz":-540,"elapsed":36,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"6c7d6cee-7c6b-4363-c603-8271ad667801"},"source":["data.columns"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'gender', 'name', 'accords', 'review', 'tokenized',\n","       'only_english', 'longer_than_2_A', 'stopwords_removed', 'lemmatizated'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"JFUurG_tuuhl","executionInfo":{"status":"ok","timestamp":1622006691712,"user_tz":-540,"elapsed":24,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"0d97d1c9-3d7f-4bbe-a4d6-ec1f7e4b9551"},"source":["data = data.drop(\"Unnamed: 0\", axis =1)\n","data.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gender</th>\n","      <th>name</th>\n","      <th>accords</th>\n","      <th>review</th>\n","      <th>tokenized</th>\n","      <th>only_english</th>\n","      <th>longer_than_2_A</th>\n","      <th>stopwords_removed</th>\n","      <th>lemmatizated</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>Got a sample of this today, and my 9 year old ...</td>\n","      <td>['got', 'a', 'sample', 'of', 'this', 'today', ...</td>\n","      <td>['got', 'a', 'sample', 'of', 'this', 'today', ...</td>\n","      <td>['got', 'sample', 'this', 'today', 'and', 'yea...</td>\n","      <td>['got', 'sample', 'today', 'year', 'old', 'dau...</td>\n","      <td>['get', 'sample', 'today', 'year', 'old', 'dau...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>First impressions. Test on blotter.\\r\\nI have ...</td>\n","      <td>['first', 'impressions.', 'test', 'on', 'blott...</td>\n","      <td>['first', 'impressions', 'test', 'on', 'blotte...</td>\n","      <td>['first', 'impressions', 'test', 'blotter', 'h...</td>\n","      <td>['first', 'impressions', 'test', 'blotter', 'h...</td>\n","      <td>['first', 'impression', 'test', 'blotter', 'he...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>This perfume reminds me of my best friend. Act...</td>\n","      <td>['this', 'perfume', 'reminds', 'me', 'of', 'my...</td>\n","      <td>['this', 'perfume', 'reminds', 'me', 'of', 'my...</td>\n","      <td>['this', 'perfume', 'reminds', 'best', 'friend...</td>\n","      <td>['perfume', 'reminds', 'best', 'friend', 'actu...</td>\n","      <td>['perfume', 'reminds', 'best', 'friend', 'actu...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>Imagine tripping over your own feet and fallin...</td>\n","      <td>['imagine', 'tripping', 'over', 'your', 'own',...</td>\n","      <td>['imagine', 'tripping', 'over', 'your', 'own',...</td>\n","      <td>['imagine', 'tripping', 'over', 'your', 'own',...</td>\n","      <td>['imagine', 'tripping', 'feet', 'falling', 'fa...</td>\n","      <td>['imagine', 'trip', 'foot', 'fall', 'face', 'f...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>Gorgeous Gorgeous Blend ..\\r\\nLove the scent.....</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', '..', 'love'...</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', '', 'love', ...</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', 'love', 'the...</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', 'love', 'sce...</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', 'love', 'sce...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   gender  ...                                       lemmatizated\n","0  female  ...  ['get', 'sample', 'today', 'year', 'old', 'dau...\n","1  female  ...  ['first', 'impression', 'test', 'blotter', 'he...\n","2  female  ...  ['perfume', 'reminds', 'best', 'friend', 'actu...\n","3  female  ...  ['imagine', 'trip', 'foot', 'fall', 'face', 'f...\n","4  female  ...  ['gorgeous', 'gorgeous', 'blend', 'love', 'sce...\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"Y1Jib_aLu4wL","executionInfo":{"status":"ok","timestamp":1622006691713,"user_tz":-540,"elapsed":23,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"b4f39006-8099-412f-e3d6-3429880fcbb5"},"source":["label = label.drop(\"Unnamed: 0\", axis =1)\n","label.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Alien Mugler for women</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Coco Mademoiselle Chanel for women</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Black Orchid Tom Ford for women</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Black Opium Yves Saint Laurent for women</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hypnotic Poison Christian Dior for women</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       name  label\n","0                    Alien Mugler for women    2.0\n","1        Coco Mademoiselle Chanel for women    2.0\n","2           Black Orchid Tom Ford for women    2.0\n","3  Black Opium Yves Saint Laurent for women    2.0\n","4  Hypnotic Poison Christian Dior for women    2.0"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"-dTbKL8nvUJq","executionInfo":{"status":"ok","timestamp":1622006691713,"user_tz":-540,"elapsed":22,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["#label추가하기\n","perfume = pd.merge(data,label, on = \"name\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"JWZt1ZoIxpht","executionInfo":{"status":"ok","timestamp":1622006691714,"user_tz":-540,"elapsed":22,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"5c96fbaf-2771-40d5-e325-0659191a4cb8"},"source":["perfume.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gender</th>\n","      <th>name</th>\n","      <th>accords</th>\n","      <th>review</th>\n","      <th>tokenized</th>\n","      <th>only_english</th>\n","      <th>longer_than_2_A</th>\n","      <th>stopwords_removed</th>\n","      <th>lemmatizated</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>Got a sample of this today, and my 9 year old ...</td>\n","      <td>['got', 'a', 'sample', 'of', 'this', 'today', ...</td>\n","      <td>['got', 'a', 'sample', 'of', 'this', 'today', ...</td>\n","      <td>['got', 'sample', 'this', 'today', 'and', 'yea...</td>\n","      <td>['got', 'sample', 'today', 'year', 'old', 'dau...</td>\n","      <td>['get', 'sample', 'today', 'year', 'old', 'dau...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>First impressions. Test on blotter.\\r\\nI have ...</td>\n","      <td>['first', 'impressions.', 'test', 'on', 'blott...</td>\n","      <td>['first', 'impressions', 'test', 'on', 'blotte...</td>\n","      <td>['first', 'impressions', 'test', 'blotter', 'h...</td>\n","      <td>['first', 'impressions', 'test', 'blotter', 'h...</td>\n","      <td>['first', 'impression', 'test', 'blotter', 'he...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>This perfume reminds me of my best friend. Act...</td>\n","      <td>['this', 'perfume', 'reminds', 'me', 'of', 'my...</td>\n","      <td>['this', 'perfume', 'reminds', 'me', 'of', 'my...</td>\n","      <td>['this', 'perfume', 'reminds', 'best', 'friend...</td>\n","      <td>['perfume', 'reminds', 'best', 'friend', 'actu...</td>\n","      <td>['perfume', 'reminds', 'best', 'friend', 'actu...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>Imagine tripping over your own feet and fallin...</td>\n","      <td>['imagine', 'tripping', 'over', 'your', 'own',...</td>\n","      <td>['imagine', 'tripping', 'over', 'your', 'own',...</td>\n","      <td>['imagine', 'tripping', 'over', 'your', 'own',...</td>\n","      <td>['imagine', 'tripping', 'feet', 'falling', 'fa...</td>\n","      <td>['imagine', 'trip', 'foot', 'fall', 'face', 'f...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>female</td>\n","      <td>Alien Mugler for women</td>\n","      <td>['white floral', 'amber', 'woody']</td>\n","      <td>Gorgeous Gorgeous Blend ..\\r\\nLove the scent.....</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', '..', 'love'...</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', '', 'love', ...</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', 'love', 'the...</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', 'love', 'sce...</td>\n","      <td>['gorgeous', 'gorgeous', 'blend', 'love', 'sce...</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   gender  ... label\n","0  female  ...   2.0\n","1  female  ...   2.0\n","2  female  ...   2.0\n","3  female  ...   2.0\n","4  female  ...   2.0\n","\n","[5 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3eQS99d9msq","executionInfo":{"status":"ok","timestamp":1622006691715,"user_tz":-540,"elapsed":22,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"f781beb8-0669-4ea7-b144-2d950a5d339e"},"source":["print(perfume.isnull().sum())\n","perfume = perfume.dropna()\n","print(perfume.isnull().sum())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["gender               0\n","name                 0\n","accords              0\n","review               1\n","tokenized            0\n","only_english         0\n","longer_than_2_A      0\n","stopwords_removed    0\n","lemmatizated         0\n","label                0\n","dtype: int64\n","gender               0\n","name                 0\n","accords              0\n","review               0\n","tokenized            0\n","only_english         0\n","longer_than_2_A      0\n","stopwords_removed    0\n","lemmatizated         0\n","label                0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCJBjRHIAbhL","executionInfo":{"status":"ok","timestamp":1622006692740,"user_tz":-540,"elapsed":1038,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"b8cf11a2-40ab-435d-b184-7973d1173521"},"source":["def show_word_count_stat(data):\n","    num_word = []\n","    num_unique_words = []\n","    for item in data:\n","        num_word.append(len(str(item).split()))\n","        num_unique_words.append(len(set(str(item).split())))\n"," \n","    # 일반\n","    perfume['num_words'] = pd.Series(num_word)\n","    # 중복 제거\n","    perfume['num_unique_words'] = pd.Series(num_unique_words)\n"," \n","    x = data[0]\n","    x = str(x).split()\n","    print(len(x))\n","    print('perfume review 단어 평균 값 : ', perfume['num_words'].mean())\n","    print('perfume review 단어 중간 값', perfume['num_words'].median())\n"," \n","    print('perfume review 고유 단어 평균 값 : ', perfume['num_unique_words'].mean())\n","    print('perfume review 고유 단어 중간 값', perfume['num_unique_words'].median())\n"," \n","show_word_count_stat(perfume.lemmatizated)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["76\n","perfume review 단어 평균 값 :  45.16187600590575\n","perfume review 단어 중간 값 33.0\n","perfume review 고유 단어 평균 값 :  38.351977228289066\n","perfume review 고유 단어 중간 값 30.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M4teppsTinsl"},"source":["## 훈련데이터 준비"]},{"cell_type":"code","metadata":{"id":"H5jBTzhN0uQc","executionInfo":{"status":"ok","timestamp":1622006694830,"user_tz":-540,"elapsed":2092,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["#lemmatizated 데이터가 string형태로 들어가있음. \n","#re.compile을 이용해서 영어만 뽑아 리스트형태로 저장\n","import re\n","def only_english(text):\n","  english = re.compile('[A-Za-z]+').findall(text)\n","  return english\n","perfume[\"lemmatizated_2\"] = perfume[\"lemmatizated\"].apply(only_english)\n","perfume[\"lemmatizated_str\"] = perfume[\"lemmatizated_2\"].str.join(' ')"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-DI2km3iaEU","executionInfo":{"status":"ok","timestamp":1622006694832,"user_tz":-540,"elapsed":5,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["X = list(perfume[\"lemmatizated_str\"])\n","y = list(perfume[\"label\"].astype(int))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"fa44Wf4FhuM8","executionInfo":{"status":"ok","timestamp":1622006708897,"user_tz":-540,"elapsed":14069,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["#위 코드와의 차이점 :\n","from sklearn.model_selection import train_test_split\n","X = np.asarray(X)\n","y = np.asarray(y)\n","X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,test_size=0.5)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LeLOLz_ncAd","executionInfo":{"status":"ok","timestamp":1622006708900,"user_tz":-540,"elapsed":8,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"d144ad19-082f-4127-a315-0202326e833e"},"source":["X_train, y_train, len(X_train),len(X_test)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array(['feel like linterdit way try achieve execute well tuberose still strong linear like way think patchouli help make less sickly gummy sweet combine ambroxan make earthy complex bergamot first spray pear lingers add fresh watery lightness surface could smell come arm move around spray impressed silage unfortunately huge fan tuberoseheavy scent wouldnt purchase bottle think nice',\n","        'pinnacle gourmand fragrance scream delicious invite cozy love pineapple hazelnut nut cream straight smell like nutella begin sweet juicy pineapple note also begin smell vanilla blend chocolate fragrance dry get smooth patchouli base add spice surprise mugler fan usually patchouli main accord mugler fragrance bad thing actually love patchouli personally version blend smoothly background note allow experience note blend together make interesting invite enjoy nose enjoy even challenge fragrance line bother personally challenge many strong patchouli base many gravitate perfume patchouli note tone background nose many others would agree make perfume feel dare say good version original exquisite perfume highly recommend try buy buy back bottle',\n","        'perfume make happy reminds carefree day young beach play sand absolute beast mode perfume though find spray need unless want gas everyone around note dominant skin pleasant though smell breeze mixed vanilla mandarin note always get compliment wear',\n","        ...,\n","        'get christmas couple year ago first come well longlasting designer mall fragrance people say bad scent ever ridiculous one declare best please people unless oversprayed safe bet occasion easy see sell well mass guy own bottle could near perfect hand like would guess fragrantica reader ve get cold cloudy day favorite cold sunny day favorite cold rainy day favorite you n t ever reach nice clean sufficiently blue last hella long time end even though sorta lot thing n t best anything',\n","        'headache beautiful bottle white flowernote harsh give literally headache shame whole mugler concept refillable bottle intrigue',\n","        'loll people describe masculine stay wear fruity escadas lil miss first discover fragrance smell another mom playground surprise see perform like savage wild give beast little wind ll project damn place think well fragrance warm vanilla without cloy spicy enough take seriously adult ahem without become overwhelmingly serious oriental totally playground appropriate though child fragrantica might want stay celebrity frag aisle masculine spicy'],\n","       dtype='<U7374'), array([2, 2, 2, ..., 0, 2, 2]), 37591, 37591)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xy4ZFcEKz8Ss","executionInfo":{"status":"ok","timestamp":1622006710430,"user_tz":-540,"elapsed":1534,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}},"outputId":"3d4114a2-4a15-4b27-bdaf-d7da6d687185"},"source":["max_len = max(len(l) for l in X)\n","max_len"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7374"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"SWxoqu-Cu5fg"},"source":["# 1. embedding : ELMo\n","- computes contextualized word representations using character-based word representations and biLSTM\n","- input : raw text stings or tokenized text strings\n","- 새로운 모델에 대해서 사용할때 예제를 통해서 자료구조가 어떤지 꼭 확인하기"]},{"cell_type":"markdown","metadata":{"id":"ax6iH3Ant_EL"},"source":["👉딥러닝 입문 위키독스 보고 따라한것 -> (elmo/1 -> elmo/2)\n","\n","🙅🏻‍♀️error : Signature expects multiple inputs. Use a dict. \n","\n","->해결 : signature: default (string), tokens으로 tokens에서 default형태로 바꿔서 사용\n","\n","\n","\n","👉[최종] **블로그 참고....**\n","\n","https://ichi.pro/ko/elmolo-ganglyeoghan-munmaeg-dan-eo-imbeding-eul-guchughaneun-bangbeob-al-abogi-40447472500805\n","\n","https://wikidocs.net/33930"]},{"cell_type":"markdown","metadata":{"id":"xfvDk6dS4Fut"},"source":["input 데이터를 elmo값으로 변환하여 모델 fit할때 elmo값으로 바뀐 데이터를 입력"]},{"cell_type":"code","metadata":{"id":"w2htkLIbj9VH","executionInfo":{"status":"ok","timestamp":1622006711184,"user_tz":-540,"elapsed":757,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n","\n","def elmo_vectors(x):\n","  embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n","\n","  with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    sess.run(tf.tables_initializer())\n","    # return average of ELMo features\n","    return sess.run(tf.reduce_mean(embeddings,1))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHuJZffD4Beu","executionInfo":{"status":"ok","timestamp":1622006711184,"user_tz":-540,"elapsed":8,"user":{"displayName":"Elina Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzLYHKyx5OjO7yshsFbcda5D7a_S4v6POdl6pj=s64","userId":"01997103414232308683"}}},"source":["list_train = [X_train[i:i+100] for i in range(0,X_train.shape[0],100)] #배치사이즈 :100개"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMVVZu364nP9","outputId":"e97f2b4f-07ac-4459-acef-16e3c368fd7e"},"source":["# Extract ELMo embeddings\n","elmo_train = [elmo_vectors(x) for x in list_train]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KtBy-pl14vMU"},"source":["elmo_train_new = np.concatenate(elmo_train, axis = 0)\n","elmo_test_new = np.concatenate(elmo_test, axis = 0)\n","# save elmo_train_new\n","pickle_out = open(\"elmo_train_03032019.pickle\",\"wb\")\n","pickle.dump(elmo_train_new, pickle_out)\n","pickle_out.close()\n","\n","# save elmo_test_new\n","pickle_out = open(\"elmo_test_03032019.pickle\",\"wb\")\n","pickle.dump(elmo_test_new, pickle_out)\n","pickle_out.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pww2MI_i9mJH"},"source":["from sklearn.model_selection import train_test_split\n","\n","xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, \n","                                                  y_train,  \n","                                                  random_state=42, \n","                                                  test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKfKw29r-Wpo"},"source":["model = Sequential()\n","model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(13, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","epochs = 5\n","batch_size = 64\n","\n","history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"krq1fFsi-lVR"},"source":["from sklearn.metrics import f1_score \n","preds_valid = history.predict(xvalid)\n","f1_score(yvalid, preds_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ye4fMTGFuKFq"},"source":["👇tensorflow hub tutorial보고 따라한 것\n","\n","토큰화를 그대로 input으로 사용하려고 했음 -> 문제는 어떻게 활용할지 모르겠다는거... \n","\n","\n","\n","https://tfhub.dev/google/elmo/3"]},{"cell_type":"code","metadata":{"id":"EzfjE0Ofyw_P"},"source":["elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n","\n","def embed_elmo(x):\n","  embeddings = elmo(x,\n","      signature=\"default\", #token(batchisize와 max_length) or default(string으로 batchsize만)\n","      as_dict=True)[\"elmo\"]\n","  return embeddings\n","#embeddings.shape #[훈련샘플수, 입력문자열 목록에서 가장 긴 문자열의 최대길이, ELMo벡터의 길이]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aO0ltYAxdpl"},"source":["from keras.models import Model\n","from keras.layers import Dense, Lambda, Input\n","\n","input_text = Input(shape=(1,), dtype=\"string\")\n","embedding_layer =  Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n","hidden_layer = Dense(256, activation='relu')(embedding_layer)\n","output_layer = Dense(1, activation='softmax')(hidden_layer)\n","model = Model(inputs=[input_text], outputs=output_layer)\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy', #멀티클래스 손실함수\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TwI4LEoA8qhQ"},"source":["history = model.fit(partial_x_train,\n","                    partial_y_train,\n","                    epochs=20,\n","                    batch_size=512,\n","                    validation_data=(x_val, y_val))"],"execution_count":null,"outputs":[]}]}